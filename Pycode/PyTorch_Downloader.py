import tkinter as tk
from tkinter import ttk, messagebox, scrolledtext
import threading
import platform
import sys
from pathlib import Path
import json
import time
import re
import shutil
import struct
import io
import contextlib


def resource_root() -> Path:
    """
    PyInstallerãƒãƒ³ãƒ‰ãƒ«ãƒªã‚½ãƒ¼ã‚¹ã‚’å«ã‚€ãƒ•ã‚©ãƒ«ãƒ€ã¸ã®ãƒ‘ã‚¹ã‚’è¿”ã™
    Return the path to the folder that contains bundled resources (for PyInstaller)
    """
    if getattr(sys, "frozen", False):  # PyInstallerã§ã®å®Ÿè¡Œæ™‚ / When running under PyInstaller
        return Path(sys._MEIPASS)
    return Path(__file__).parent


class PyTorchDownloader:
    """
    PyTorchã¨Whisperã®ä¾å­˜é–¢ä¿‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼ (Dependency Downloader for PyTorch & Whisper)
    ç‰¹å®šã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«PyTorchã¨Whisperã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦å‹•çš„ã«ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™
    (Downloads PyTorch & Whisper to a specific directory for dynamic loading)
    """

    def __init__(self):
        # åŸºæœ¬å±æ€§ã®åˆæœŸåŒ– / Initialize core attributes
        self.target_dir = Path("pytorch_libs")
        self.is_downloading = False
        self.download_thread = None
        self.current_language = "en"  # Default to English

        # Initialize translations
        self.init_translations()

        # ã‚«ãƒ©ãƒ¼ãƒ†ãƒ¼ãƒ / Color theme
        self.colors = {
            'primary': '#2E3440',
            'accent': '#5E81AC',
            'success': '#A3BE8C',
            'warning': '#EBCB8B',
            'danger': '#BF616A',
            'text': '#2E3440',
            'text_light': '#4C566A',
            'background': '#ECEFF4',
            'surface': '#FFFFFF',
            'border': '#D8DEE9'
        }

        # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æ¤œå‡º / Detect platform (Windows/Linux etc.)
        self.detect_platform()

        # GUIã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— / Setup GUI
        self.setup_gui()

        # æ—¢å­˜ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã®ç¢ºèª / Check if installation already exists
        self.check_existing_installation()

    def init_translations(self):
        """Initialize all UI text translations"""
        self.translations = {
            "en": {
                "window_title": "PyTorch Downloader",
                "header_title": "PyTorch & Whisper Downloader",
                "header_subtitle": "Downloads required dependencies for audio subtitle system",
                "system_info": "System Information:",
                "version_selection": "PyTorch Version Selection:",
                "cpu_version": "CPU Version",
                "cuda_version": "CUDA Version (GPU acceleration)",
                "not_detected": "Not detected",
                "install_dir": "Install directory:",
                "status": "Status:",
                "ready": "Ready",
                "download_log": "Download Log:",
                "start_download": "ğŸš€ Start Downloading",
                "verify": "âœ”ï¸ Verify",
                "close": "âŒ Close",
                "language": "Language:",
                "platform_detected": "Detected platform:",
                "existing_dir": "Existing directory detected:",
                "cleaning_up": "Cleaning up existing installations...",
                "cleanup_status": "Cleaning up...",
                "cleanup_warning": "Warning: Failed to remove",
                "cleanup_complete": "Cleanup complete:",
                "items_removed": "items removed",
                "warning": "Warning",
                "already_downloading": "Already downloading",
                "confirm": "Confirm",
                "download_confirm": "Download to {}? Existing files will be removed.",
                "error": "Error",
                "cuda_error": "Unsupported or missing CUDA Toolkit.",
                "pip_error": "pip Error",
                "pip_import_failed": "Failed to import pip:",
                "embedded_wheel": "Using embedded wheel:",
                "no_embedded_wheel": "Embedded wheel not found â†’ fallback to PyPI",
                "download_complete": "Done",
                "complete": "Complete",
                "download_success_msg": "Download of PyTorch + Whisper has completed!\nYou may click 'Verify' or close this window.",
                "download_failed": "Download Failed",
                "verify_start": "Start verifying",
                "verifying": "Verifying...",
                "verify_success": "Verification Succeeded",
                "verify_success_msg": "PyTorch & Whisper have been successfully installed.",
                "verify_failed": "Verify Failed",
                "import_error": "Import error:",
                "verify_failed_msg": "Failed to import: {}",
                "still_downloading": "Still downloading. Close anyway?"
            },
            "ja": {
                "window_title": "PyTorchãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼",
                "header_title": "PyTorch & Whisper ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼",
                "header_subtitle": "éŸ³å£°å­—å¹•ã‚·ã‚¹ãƒ†ãƒ ã«å¿…è¦ãªä¾å­˜é–¢ä¿‚ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™",
                "system_info": "ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±:",
                "version_selection": "PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³é¸æŠ:",
                "cpu_version": "CPUç‰ˆ",
                "cuda_version": "CUDAç‰ˆ (GPUåŠ é€Ÿ)",
                "not_detected": "æœªæ¤œå‡º",
                "install_dir": "ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª:",
                "status": "çŠ¶æ…‹:",
                "ready": "æº–å‚™å®Œäº†",
                "download_log": "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ­ã‚°:",
                "start_download": "ğŸš€ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹",
                "verify": "âœ”ï¸ æ¤œè¨¼",
                "close": "âŒ é–‰ã˜ã‚‹",
                "language": "è¨€èª:",
                "platform_detected": "æ¤œå‡ºã•ã‚ŒãŸãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ :",
                "existing_dir": "æ—¢å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œå‡º:",
                "cleaning_up": "æ—¢å­˜ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...",
                "cleanup_status": "ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...",
                "cleanup_warning": "è­¦å‘Š: å‰Šé™¤å¤±æ•—",
                "cleanup_complete": "ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†:",
                "items_removed": "å€‹å‰Šé™¤",
                "warning": "è­¦å‘Š",
                "already_downloading": "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã§ã™",
                "confirm": "ç¢ºèª",
                "download_confirm": "{} ã¸ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã‹ï¼Ÿæ—¢å­˜ã®å†…å®¹ã¯å‰Šé™¤ã•ã‚Œã¾ã™ã€‚",
                "error": "ã‚¨ãƒ©ãƒ¼",
                "cuda_error": "CUDA Toolkit ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
                "pip_error": "pip ã‚¨ãƒ©ãƒ¼",
                "pip_import_failed": "pip ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ:",
                "embedded_wheel": "åŒæ¢±wheelã‚’ä½¿ç”¨ã—ã¾ã™:",
                "no_embedded_wheel": "åŒæ¢±wheelãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸâ†’PyPIã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«",
                "download_complete": "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†",
                "complete": "å®Œäº†",
                "download_success_msg": "PyTorch + Whisper ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸï¼\nâœ”ï¸ã€æ¤œè¨¼ã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã‹ã€ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‰ã˜ã¦ãã ã•ã„ã€‚",
                "download_failed": "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—",
                "verify_start": "æ¤œè¨¼é–‹å§‹",
                "verifying": "æ¤œè¨¼ä¸­...",
                "verify_success": "æ¤œè¨¼æˆåŠŸ",
                "verify_success_msg": "PyTorchã¨WhisperãŒæ­£ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¾ã—ãŸã€‚",
                "verify_failed": "æ¤œè¨¼å¤±æ•—",
                "import_error": "ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼:",
                "verify_failed_msg": "ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚å†åº¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚\n{}",
                "still_downloading": "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã§ã™ãŒçµ‚äº†ã—ã¾ã™ã‹ï¼Ÿ"
            },
            "zh": {
                "window_title": "PyTorch ä¸‹è½½å™¨",
                "header_title": "PyTorch & Whisper ä¸‹è½½å™¨",
                "header_subtitle": "ä¸‹è½½éŸ³é¢‘å­—å¹•ç³»ç»Ÿæ‰€éœ€çš„ä¾èµ–é¡¹",
                "system_info": "ç³»ç»Ÿä¿¡æ¯ï¼š",
                "version_selection": "PyTorchç‰ˆæœ¬é€‰æ‹©ï¼š",
                "cpu_version": "CPUç‰ˆ",
                "cuda_version": "CUDAç‰ˆ (GPUåŠ é€Ÿ)",
                "not_detected": "æœªæ£€æµ‹åˆ°",
                "install_dir": "å®‰è£…ç›®å½•ï¼š",
                "status": "çŠ¶æ€ï¼š",
                "ready": "å‡†å¤‡å°±ç»ª",
                "download_log": "ä¸‹è½½æ—¥å¿—ï¼š",
                "start_download": "ğŸš€ å¼€å§‹ä¸‹è½½",
                "verify": "âœ”ï¸ éªŒè¯",
                "close": "âŒ å…³é—­",
                "language": "è¯­è¨€ï¼š",
                "platform_detected": "æ£€æµ‹åˆ°çš„å¹³å°ï¼š",
                "existing_dir": "æ£€æµ‹åˆ°ç°æœ‰ç›®å½•ï¼š",
                "cleaning_up": "æ­£åœ¨æ¸…ç†ç°æœ‰å®‰è£…...",
                "cleanup_status": "æ¸…ç†ä¸­...",
                "cleanup_warning": "è­¦å‘Šï¼šåˆ é™¤å¤±è´¥",
                "cleanup_complete": "æ¸…ç†å®Œæˆï¼š",
                "items_removed": "ä¸ªé¡¹ç›®å·²åˆ é™¤",
                "warning": "è­¦å‘Š",
                "already_downloading": "æ­£åœ¨ä¸‹è½½ä¸­",
                "confirm": "ç¡®è®¤",
                "download_confirm": "è¦ä¸‹è½½åˆ° {} å—ï¼Ÿç°æœ‰å†…å®¹å°†è¢«åˆ é™¤ã€‚",
                "error": "é”™è¯¯",
                "cuda_error": "æœªæ‰¾åˆ°æˆ–ä¸æ”¯æŒ CUDA Toolkitã€‚",
                "pip_error": "pip é”™è¯¯",
                "pip_import_failed": "å¯¼å…¥ pip å¤±è´¥ï¼š",
                "embedded_wheel": "ä½¿ç”¨å†…ç½® wheelï¼š",
                "no_embedded_wheel": "æœªæ‰¾åˆ°å†…ç½® wheel â†’ ä» PyPI å®‰è£…",
                "download_complete": "ä¸‹è½½å®Œæˆ",
                "complete": "å®Œæˆ",
                "download_success_msg": "PyTorch + Whisper ä¸‹è½½å®Œæˆï¼\næ‚¨å¯ä»¥ç‚¹å‡»éªŒè¯æˆ–å…³é—­æ­¤çª—å£ã€‚",
                "download_failed": "ä¸‹è½½å¤±è´¥",
                "verify_start": "å¼€å§‹éªŒè¯",
                "verifying": "éªŒè¯ä¸­...",
                "verify_success": "éªŒè¯æˆåŠŸ",
                "verify_success_msg": "PyTorch å’Œ Whisper å·²æˆåŠŸå®‰è£…ã€‚",
                "verify_failed": "éªŒè¯å¤±è´¥",
                "import_error": "å¯¼å…¥é”™è¯¯ï¼š",
                "verify_failed_msg": "å¯¼å…¥å¤±è´¥ï¼š{}",
                "still_downloading": "ä»åœ¨ä¸‹è½½ä¸­ã€‚ç¡®å®šè¦å…³é—­å—ï¼Ÿ"
            },
            "ko": {
                "window_title": "PyTorch ë‹¤ìš´ë¡œë”",
                "header_title": "PyTorch & Whisper ë‹¤ìš´ë¡œë”",
                "header_subtitle": "ì˜¤ë””ì˜¤ ìë§‰ ì‹œìŠ¤í…œì— í•„ìš”í•œ ì¢…ì†ì„±ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤",
                "system_info": "ì‹œìŠ¤í…œ ì •ë³´:",
                "version_selection": "PyTorch ë²„ì „ ì„ íƒ:",
                "cpu_version": "CPU ë²„ì „",
                "cuda_version": "CUDA ë²„ì „ (GPU ê°€ì†)",
                "not_detected": "ê°ì§€ë˜ì§€ ì•ŠìŒ",
                "install_dir": "ì„¤ì¹˜ ë””ë ‰í† ë¦¬:",
                "status": "ìƒíƒœ:",
                "ready": "ì¤€ë¹„ ì™„ë£Œ",
                "download_log": "ë‹¤ìš´ë¡œë“œ ë¡œê·¸:",
                "start_download": "ğŸš€ ë‹¤ìš´ë¡œë“œ ì‹œì‘",
                "verify": "âœ”ï¸ ê²€ì¦",
                "close": "âŒ ë‹«ê¸°",
                "language": "ì–¸ì–´:",
                "platform_detected": "ê°ì§€ëœ í”Œë«í¼:",
                "existing_dir": "ê¸°ì¡´ ë””ë ‰í† ë¦¬ ê°ì§€:",
                "cleaning_up": "ê¸°ì¡´ ì„¤ì¹˜ë¥¼ ì •ë¦¬í•˜ëŠ” ì¤‘...",
                "cleanup_status": "ì •ë¦¬ ì¤‘...",
                "cleanup_warning": "ê²½ê³ : ì œê±° ì‹¤íŒ¨",
                "cleanup_complete": "ì •ë¦¬ ì™„ë£Œ:",
                "items_removed": "ê°œ í•­ëª© ì œê±°ë¨",
                "warning": "ê²½ê³ ",
                "already_downloading": "ì´ë¯¸ ë‹¤ìš´ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤",
                "confirm": "í™•ì¸",
                "download_confirm": "{} ì— ë‹¤ìš´ë¡œë“œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? ê¸°ì¡´ íŒŒì¼ì€ ì‚­ì œë©ë‹ˆë‹¤.",
                "error": "ì˜¤ë¥˜",
                "cuda_error": "CUDA íˆ´í‚·ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                "pip_error": "pip ì˜¤ë¥˜",
                "pip_import_failed": "pip ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨:",
                "embedded_wheel": "ë‚´ì¥ wheel ì‚¬ìš©:",
                "no_embedded_wheel": "ë‚´ì¥ wheelì„ ì°¾ì„ ìˆ˜ ì—†ìŒ â†’ PyPIì—ì„œ ì„¤ì¹˜",
                "download_complete": "ë‹¤ìš´ë¡œë“œ ì™„ë£Œ",
                "complete": "ì™„ë£Œ",
                "download_success_msg": "PyTorch + Whisper ë‹¤ìš´ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n'ê²€ì¦'ì„ í´ë¦­í•˜ê±°ë‚˜ ì´ ì°½ì„ ë‹«ìœ¼ì„¸ìš”.",
                "download_failed": "ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨",
                "verify_start": "ê²€ì¦ ì‹œì‘",
                "verifying": "ê²€ì¦ ì¤‘...",
                "verify_success": "ê²€ì¦ ì„±ê³µ",
                "verify_success_msg": "PyTorchì™€ Whisperê°€ ì„±ê³µì ìœ¼ë¡œ ì„¤ì¹˜ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "verify_failed": "ê²€ì¦ ì‹¤íŒ¨",
                "import_error": "ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜:",
                "verify_failed_msg": "ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {}",
                "still_downloading": "ì•„ì§ ë‹¤ìš´ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤. ê·¸ë˜ë„ ë‹«ìœ¼ì‹œê² ìŠµë‹ˆê¹Œ?"
            }
        }

    def t(self, key):
        """Get translated text for current language"""
        return self.translations.get(self.current_language, self.translations["en"]).get(key, key)

    def detect_platform(self):
        """
        Windowsãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’æ¤œå‡ºã—ã€platform_tagã‚’è¨­å®š
        Detect the platform (especially Windows) and assign self.platform_tag
        """
        if platform.system() == "Windows":
            # 32bit vs 64bit
            if struct.calcsize("P") * 8 == 64:
                self.platform_tag = "win_amd64"
            else:
                self.platform_tag = "win32"
        else:
            # Linuxãªã©ä»–OS / For Linux or other OS
            machine = platform.machine().lower()
            if machine in ['x86_64', 'amd64']:
                self.platform_tag = "linux_x86_64"
            elif machine == 'aarch64':
                self.platform_tag = "linux_aarch64"
            else:
                self.platform_tag = platform.machine()

        # GUIãŒæœªæ§‹ç¯‰ã®å ´åˆã¯ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ› / Print to console if GUI is not built yet
        if hasattr(self, 'root'):
            self.log_output(f"{self.t('platform_detected')} {self.platform_tag}")
        else:
            print(f"[{time.strftime('%H:%M:%S')}] "
                  f"Detected platform: {self.platform_tag}")

    def setup_gui(self):
        """
        GUIã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’åˆæœŸåŒ–ã—ã€é…ç½®ã‚’è¡Œã†
        Initialize the GUI window and place widgets
        """
        self.root = tk.Tk()
        self.root.title(self.t("window_title"))
        self.root.geometry("1200x900")

        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ä¸­å¤®å¯„ã› / Center the window on screen
        self.root.update_idletasks()
        w, h = self.root.winfo_width(), self.root.winfo_height()
        ws, hs = self.root.winfo_screenwidth(), self.root.winfo_screenheight()
        x, y = (ws // 2 - w // 2), (hs // 2 - h // 2)
        self.root.geometry(f"{w}x{h}+{x}+{y}")
        self.root.configure(bg=self.colors['background'])

        main = tk.Frame(self.root, bg=self.colors['background'])
        main.pack(fill=tk.BOTH, expand=True, padx=20, pady=20)

        self.create_header(main)
        self.create_config_section(main)
        self.create_status_section(main)
        self.create_output_section(main)
        self.create_control_buttons(main)

        # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æƒ…å ±ã‚’GUIã«è¡¨ç¤º / Log platform in the GUI
        self.log_output(f"{self.t('platform_detected')} {self.platform_tag}")

        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦çµ‚äº†æ™‚ã®ã‚¤ãƒ™ãƒ³ãƒˆè¨­å®š / Attach on_closing for window close
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)

    def create_header(self, parent):
        """
        ãƒ˜ãƒƒãƒ€éƒ¨åˆ†ã®UIã‚’ä½œæˆ / Create the header UI
        """
        header = tk.Frame(parent, bg=self.colors['background'])
        header.pack(fill=tk.X, pady=(0, 20))

        # Create a frame for the title and language selector
        title_frame = tk.Frame(header, bg=self.colors['background'])
        title_frame.pack(fill=tk.X)

        # Left side - titles
        left_frame = tk.Frame(title_frame, bg=self.colors['background'])
        left_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)

        self.header_title_label = tk.Label(
            left_frame,
            text=self.t("header_title"),
            font=('Yu Gothic', 20, 'bold'),
            fg=self.colors['primary'],
            bg=self.colors['background']
        )
        self.header_title_label.pack()

        self.header_subtitle_label = tk.Label(
            left_frame,
            text=self.t("header_subtitle"),
            font=('Segoe UI', 11),
            fg=self.colors['text_light'],
            bg=self.colors['background']
        )
        self.header_subtitle_label.pack(pady=(5, 0))

        # Right side - language selector
        lang_frame = tk.Frame(title_frame, bg=self.colors['background'])
        lang_frame.pack(side=tk.RIGHT, padx=10)

        self.lang_label = tk.Label(
            lang_frame,
            text=self.t("language"),
            font=('Yu Gothic', 10),
            fg=self.colors['text'],
            bg=self.colors['background']
        )
        self.lang_label.pack(side=tk.LEFT, padx=(0, 5))

        # Language display names
        self.language_display = {
            "en": "en - English",
            "ja": "ja - æ—¥æœ¬èª",
            "zh": "cn - ä¸­æ–‡",
            "ko": "ko - í•œêµ­ì–´"
        }
        
        self.language_var = tk.StringVar(value=self.language_display[self.current_language])
        self.language_combo = ttk.Combobox(
            lang_frame,
            textvariable=self.language_var,
            values=list(self.language_display.values()),
            state="readonly",
            width=10,
            font=('Segoe UI', 10)
        )
        self.language_combo.pack(side=tk.LEFT)
        self.language_combo.bind("<<ComboboxSelected>>", self.on_language_change)

    def on_language_change(self, event=None):
        """Handle language change event"""
        # Get the language code from the display name
        display_name = self.language_var.get()
        for code, name in self.language_display.items():
            if name == display_name:
                self.current_language = code
                break
        self.update_all_texts()

    def update_all_texts(self):
        """Update all UI texts when language changes"""
        # Update window title
        self.root.title(self.t("window_title"))
        
        # Update header
        self.header_title_label.config(text=self.t("header_title"))
        self.header_subtitle_label.config(text=self.t("header_subtitle"))
        self.lang_label.config(text=self.t("language"))
        
        # Update config section
        self.system_info_label.config(text=self.t("system_info"))
        self.version_label.config(text=self.t("version_selection"))
        self.cpu_radio.config(text=self.t("cpu_version"))
        
        cuda_text = self.t("cuda_version")
        if self.cuda_radio['state'] == tk.DISABLED:
            cuda_text += f" - {self.t('not_detected')}"
        self.cuda_radio.config(text=cuda_text)
        
        self.install_dir_label.config(text=f"{self.t('install_dir')} {self.target_dir.absolute()}")
        
        # Update status section
        self.status_label_prefix.config(text=self.t("status"))
        if self.status_label.cget("text") in ["æº–å‚™å®Œäº†", "Ready", "å‡†å¤‡å°±ç»ª", "ì¤€ë¹„ ì™„ë£Œ"]:
            self.status_label.config(text=self.t("ready"))
        
        # Update output section
        self.log_label.config(text=self.t("download_log"))
        
        # Update buttons
        self.download_btn.config(text=self.t("start_download"))
        self.verify_btn.config(text=self.t("verify"))
        self.close_btn.config(text=self.t("close"))

    def create_config_section(self, parent):
        """
        ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ãƒ»PyTorchã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³é¸æŠãªã©ã‚’è¡Œã†è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³
        Configuration section for system info & PyTorch version selection
        """
        frame = tk.Frame(parent, bg=self.colors['surface'], relief='solid', bd=1)
        frame.pack(fill=tk.X, pady=(0, 15))

        inner = tk.Frame(frame, bg=self.colors['surface'])
        inner.pack(fill=tk.X, padx=15, pady=15)

        # ---- System Info ----
        self.system_info_label = tk.Label(
            inner,
            text=self.t("system_info"),
            font=('Yu Gothic', 12, 'bold'),
            fg=self.colors['text'],
            bg=self.colors['surface']
        )
        self.system_info_label.pack(anchor=tk.W)

        ver = sys.getwindowsversion().major
        # Windows 11 / 10 åˆ¤æ–­ (heuristics for Windows version)
        os_name = f"Windows {11 if (ver == 10 and sys.getwindowsversion().build >= 22000) else ver}"

        info = (
            f"OS: {os_name}\n"
            f"Python: {sys.version.split()[0]}\n"
            f"Arch: {platform.machine()}\n"
            f"Platform Tag: {self.platform_tag}"
        )

        tk.Label(
            inner,
            text=info,
            font=('Consolas', 10),
            fg=self.colors['text_light'],
            bg=self.colors['surface'],
            justify=tk.LEFT
        ).pack(anchor=tk.W, pady=(0, 15))

        # ---- PyTorch Version Choice ----
        self.version_label = tk.Label(
            inner,
            text=self.t("version_selection"),
            font=('Yu Gothic', 12, 'bold'),
            fg=self.colors['text'],
            bg=self.colors['surface']
        )
        self.version_label.pack(anchor=tk.W)

        self.version_var = tk.StringVar(value="cpu")
        vf = tk.Frame(inner, bg=self.colors['surface'])
        vf.pack(anchor=tk.W, pady=(0, 10))

        self.cpu_radio = tk.Radiobutton(
            vf,
            text=self.t("cpu_version"),
            variable=self.version_var,
            value="cpu",
            font=('Yu Gothic', 10),
            bg=self.colors['surface'],
            fg=self.colors['text']
        )
        self.cpu_radio.pack(side=tk.LEFT, padx=(0, 20))

        cuda_ok = self.check_cuda_available()
        cuda_text = self.t("cuda_version")
        if not cuda_ok:
            cuda_text += f" - {self.t('not_detected')}"

        self.cuda_radio = tk.Radiobutton(
            vf,
            text=cuda_text,
            variable=self.version_var,
            value="cuda",
            font=('Yu Gothic', 10),
            bg=self.colors['surface'],
            fg=self.colors['text'] if cuda_ok else self.colors['text_light'],
            state=tk.NORMAL if cuda_ok else tk.DISABLED
        )
        self.cuda_radio.pack(side=tk.LEFT)

        self.install_dir_label = tk.Label(
            inner,
            text=f"{self.t('install_dir')} {self.target_dir.absolute()}",
            font=('Yu Gothic', 10),
            fg=self.colors['text_light'],
            bg=self.colors['surface']
        )
        self.install_dir_label.pack(anchor=tk.W)

    def create_status_section(self, parent):
        """
        ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã®é€²æ—ã‚„ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¡¨ç¤º / Displays download progress and status
        """
        frame = tk.Frame(parent, bg=self.colors['surface'], relief='solid', bd=1)
        frame.pack(fill=tk.X, pady=(0, 15))

        inner = tk.Frame(frame, bg=self.colors['surface'])
        inner.pack(fill=tk.X, padx=15, pady=10)

        row = tk.Frame(inner, bg=self.colors['surface'])
        row.pack(fill=tk.X)

        self.status_label_prefix = tk.Label(
            row,
            text=self.t("status"),
            font=('Yu Gothic', 11, 'bold'),
            fg=self.colors['text'],
            bg=self.colors['surface']
        )
        self.status_label_prefix.pack(side=tk.LEFT)

        self.status_label = tk.Label(
            row,
            text=self.t("ready"),
            font=('Yu Gothic', 11),
            fg=self.colors['text_light'],
            bg=self.colors['surface']
        )
        self.status_label.pack(side=tk.RIGHT)

        self.progress_bar = ttk.Progressbar(inner, mode='indeterminate')
        self.progress_bar.pack(fill=tk.X)

    def create_output_section(self, parent):
        """
        ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ­ã‚°ã‚’è¡¨ç¤º / Section for showing download logs
        """
        frame = tk.Frame(parent, bg=self.colors['surface'], relief='solid', bd=1)
        frame.pack(fill=tk.BOTH, expand=True, pady=(0, 15))

        inner = tk.Frame(frame, bg=self.colors['surface'])
        inner.pack(fill=tk.BOTH, expand=True, padx=15, pady=10)

        self.log_label = tk.Label(
            inner,
            text=self.t("download_log"),
            font=('Yu Gothic', 11, 'bold'),
            fg=self.colors['text'],
            bg=self.colors['surface']
        )
        self.log_label.pack(anchor=tk.W)

        self.output_text = scrolledtext.ScrolledText(
            inner,
            height=10,
            font=('Consolas', 9),
            bg=self.colors['surface'],
            fg=self.colors['text'],
            wrap=tk.WORD
        )
        self.output_text.pack(fill=tk.BOTH, expand=True)

    def create_control_buttons(self, parent):
        """
        ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹ãƒ»æ¤œè¨¼ãƒ»çµ‚äº†ãƒœã‚¿ãƒ³ / Buttons to start download, verify, and close
        """
        frame = tk.Frame(parent, bg=self.colors['background'])
        frame.pack(fill=tk.X)

        self.download_btn = tk.Button(
            frame,
            text=self.t("start_download"),
            command=self.start_download,
            font=('Yu Gothic', 11, 'bold'),
            bg=self.colors['accent'],
            fg='white',
            padx=20,
            pady=10,
            bd=0,
            cursor='hand2'
        )
        self.download_btn.pack(side=tk.LEFT, padx=(0, 10))

        self.verify_btn = tk.Button(
            frame,
            text=self.t("verify"),
            command=self.verify_installation,
            font=('Yu Gothic', 11),
            bg=self.colors['success'],
            fg='white',
            padx=20,
            pady=10,
            bd=0,
            cursor='hand2',
            state=tk.DISABLED
        )
        self.verify_btn.pack(side=tk.LEFT, padx=(0, 10))

        self.close_btn = tk.Button(
            frame,
            text=self.t("close"),
            command=self.on_closing,
            font=('Yu Gothic', 11),
            bg=self.colors['danger'],
            fg='white',
            padx=20,
            pady=10,
            bd=0,
            cursor='hand2'
        )
        self.close_btn.pack(side=tk.RIGHT)

    def check_cuda_available(self):
        """
        CUDAãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ(nvcc)ãŒä½¿ãˆã‚‹ã‹ç¢ºèª
        Check if CUDA Toolkit (nvcc) is available
        """
        try:
            import subprocess
            out = subprocess.check_output(['nvcc', '--version'], stderr=subprocess.STDOUT, text=True)
            return 'release' in out.lower()
        except (FileNotFoundError, subprocess.CalledProcessError):
            return False

    def check_existing_installation(self):
        """
        ã™ã§ã«pytorch_libsãƒ•ã‚©ãƒ«ãƒ€ãŒã‚ã‚‹å ´åˆã‚’ç¢ºèª / Check if the target_dir already exists
        """
        if self.target_dir.exists():
            self.log_output(f"{self.t('existing_dir')} {self.target_dir}")
            self.verify_btn.config(state=tk.NORMAL)

    def log_output(self, message):
        """
        ãƒ­ã‚°ã‚¨ãƒªã‚¢ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡ºåŠ› / Output message to log (ScrolledText)
        """
        def update():
            self.output_text.insert(tk.END, f"[{time.strftime('%H:%M:%S')}] {message}\n")
            self.output_text.see(tk.END)
        self.root.after(0, update)

    def update_status(self, status, color=None):
        """
        ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ©ãƒ™ãƒ«ã‚’æ›´æ–° / Update status label
        """
        def update():
            self.status_label.config(text=status)
            if color:
                self.status_label.config(fg=color)
        self.root.after(0, update)

    def clean_pytorch_installation(self):
        """
        æ—¢å­˜ã®PyTorchã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’å‰Šé™¤ã—ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— / Clean up existing PyTorch installations
        """
        self.log_output(self.t("cleaning_up"))
        self.update_status(self.t("cleanup_status"), self.colors['warning'])

        patterns = ["torch*", "torchvision*", "torchaudio*", "torchgen"]
        removed = 0

        for pat in patterns:
            for path in self.target_dir.glob(pat):
                try:
                    if path.is_dir():
                        shutil.rmtree(path)
                    else:
                        path.unlink(missing_ok=True)
                    removed += 1
                except Exception as e:
                    self.log_output(f"{self.t('cleanup_warning')} {pat}: {e}")

        self.log_output(f"{self.t('cleanup_complete')} {removed} {self.t('items_removed')}")
        time.sleep(1)

    def start_download(self):
        """
        ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ / Start the download process
        """
        if self.is_downloading:
            messagebox.showwarning(self.t("warning"), self.t("already_downloading"))
            return

        if not messagebox.askyesno(self.t("confirm"),
                                   self.t("download_confirm").format(self.target_dir)):
            return

        self.is_downloading = True
        self.download_btn.config(state=tk.DISABLED)
        self.progress_bar.start()
        self.output_text.delete(1.0, tk.END)

        threading.Thread(target=self.download_dependencies, daemon=True).start()

    def get_cuda_index_url(self):
        """
        nvccã‹ã‚‰CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å–å¾—ã—ã¦PyTorchã®WHLãƒªãƒã‚¸ãƒˆãƒªURLã‚’ç”Ÿæˆ
        Get CUDA version from nvcc and return the PyTorch wheels index URL
        """
        try:
            import subprocess
            out = subprocess.check_output(['nvcc', '--version'], text=True)
            m = re.search(r'release\s+([0-9]+)\.([0-9]+)', out)
            if not m:
                raise ValueError
            ver = m.group(1) + m.group(2)
            if ver not in ('118', '126', '128'):
                raise ValueError
        except Exception:
            messagebox.showerror(self.t("error"), self.t("cuda_error"))
            return None
        return f"https://download.pytorch.org/whl/cu{ver}"

    def _run_pip(self, pip_args: list, label: str):
        """
        pip._internalã‚’ä½¿ã„ã€ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’ä½¿ã‚ãšç›´æ¥pipã‚’å‘¼ã³å‡ºã™
        Use pip._internal directly (no separate subprocess) to run pip commands
        """
        try:
            # é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆ / Lazy import to avoid overhead on GUI startup
            from pip._internal.cli.main import main as pip_main
        except Exception as e:
            messagebox.showerror(self.t("pip_error"), f"{self.t('pip_import_failed')} {e}")
            raise

        full_cmd = pip_args[:]
        self.log_output(f"[{label}] pip {' '.join(full_cmd)}")

        # pip å‡ºåŠ›ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ / Capture pip output
        output_buffer = io.StringIO()
        with contextlib.redirect_stdout(output_buffer), contextlib.redirect_stderr(output_buffer):
            try:
                rc = pip_main(full_cmd)  # pip_main returns 0 if success
            except SystemExit as e:
                rc = e.code if e.code is not None else 1

        # ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ãŸå‡ºåŠ›ã‚’ãƒ­ã‚°è¡¨ç¤º / Show captured output in logs
        output = output_buffer.getvalue()
        if output:
            for line in output.splitlines():
                if line.strip():
                    self.log_output(line)

        if rc != 0:
            raise RuntimeError(f"{label} failed with exit-code {rc}")

    def download_dependencies(self):
        """
        PyTorchã€Whisperã€ãŠã‚ˆã³é–¢é€£ä¾å­˜é–¢ä¿‚ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹
        Download & install PyTorch, Whisper, and related dependencies
        """
        try:
            self.target_dir.mkdir(exist_ok=True)
            self.clean_pytorch_installation()

            PY_VER = f"{sys.version_info.major}{sys.version_info.minor}"
            if self.version_var.get() == "cuda":
                url = self.get_cuda_index_url()
                # CUDA URLãŒNoneã®å ´åˆã€æ—©æœŸçµ‚äº† / If None, exit early (error already shown)
                if not url:
                    return
            else:
                url = "https://download.pytorch.org/whl/cpu"

            # ---------- Step1ï¼š Torch Core ----------
            core_pkgs = ["torch", "torchvision", "torchaudio", "numpy"]
            self.log_output(f"Index URL (core): {url}")
            self._run_pip([
                "install", *core_pkgs,
                "--index-url", url,
                "--only-binary", ":all:",
                "--implementation", "cp",
                "--python-version", PY_VER,
                "--platform", self.platform_tag,
                "--upgrade", "--no-cache-dir",
                "--target", str(self.target_dir)
            ], "pytorch-core")

            # ---------- Step2ï¼š Other Dependencies ----------
            extra_pkgs = ["tqdm", "mpmath", "tiktoken", "regex", "numba", "llvmlite"]
            self.log_output("Index URL (extra): https://pypi.org/simple")
            self._run_pip([
                "install", *extra_pkgs,
                "--only-binary", ":all:",  # ã“ã‚Œã‚‰ã¯PyPIã«wheelãŒã‚ã‚‹ / These have wheels on PyPI
                "--upgrade", "--no-cache-dir",
                "--target", str(self.target_dir)
            ], "pytorch-extras")

            # ---------- Step3ï¼š Whisper ----------
            wheel_path = self._find_embedded_whisper_wheel()
            # exeç‰ˆã¯third_party_wheelså†…ã«openai_whisperã®whlãŒå«ã¾ã‚Œã‚‹ / For exe bundling, the wheel might be included
            if wheel_path and wheel_path.exists():
                self.log_output(f"{self.t('embedded_wheel')} {wheel_path.name}")
                self._run_pip([
                    "install", str(wheel_path),
                    "--no-deps", "--upgrade", "--no-cache-dir",
                    "--target", str(self.target_dir)
                ], "openai-whisper")
            else:
                self.log_output(self.t("no_embedded_wheel"))
                self._run_pip([
                    "install", "openai-whisper",
                    "--only-binary", ":all:",  # PyPIä¸Šã«å…¬å¼wheelæœ‰ / Official wheel on PyPI
                    "--no-deps", "--upgrade", "--no-cache-dir",
                    "--target", str(self.target_dir)
                ], "openai-whisper")

            # ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æƒ…å ±ã®æ›¸ãè¾¼ã¿ / Write installation info
            install_info = {
                "version": self.version_var.get(),
                "time": time.strftime("%Y-%m-%d %H:%M:%S"),
                "platform": self.platform_tag,
                "python": sys.version.split()[0]
            }
            with open(self.target_dir / "pytorch_whisper_installed.json", "w") as f:
                json.dump(install_info, f, indent=2)

            self.update_status(self.t("download_complete"), self.colors['success'])
            self.root.after(0, lambda: self.verify_btn.config(state=tk.NORMAL))
            self.root.after(0, lambda: messagebox.showinfo(
                self.t("complete"),
                self.t("download_success_msg")
            ))
        except Exception as e:
            self.log_output(f"{self.t('error')}: {e}")
            self.update_status(self.t("download_failed"), self.colors['danger'])
            messagebox.showerror(self.t("error"), str(e))
        finally:
            self.is_downloading = False
            self.root.after(0, lambda: self.download_btn.config(state=tk.NORMAL))
            self.root.after(0, lambda: self.progress_bar.stop())

    def _find_embedded_whisper_wheel(self) -> Path | None:
        """
        exeç‰ˆã«åŒæ¢±ã•ã‚Œã¦ã„ã‚‹openai_whisperã®wheelãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™ / 
        Look for an embedded openai_whisper wheel in the bundled folder
        """
        wheels_dir = resource_root() / "third_party_wheels"
        try:
            return next(wheels_dir.glob("openai_whisper-*.whl"))
        except StopIteration:
            return None

    def verify_installation(self):
        """
        ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸPyTorch/WhisperãŒæ­£å¸¸ã«importå¯èƒ½ã‹æ¤œè¨¼
        Verify that downloaded PyTorch/Whisper can be imported successfully
        """
        self.log_output(self.t("verify_start"))
        self.update_status(self.t("verifying"), self.colors['accent'])

        try:
            # ãƒ‘ã‚¹ã‚’ä¸€æ™‚çš„ã«æŒ¿å…¥ / Temporarily modify sys.path
            orig = sys.path.copy()
            sys.path.insert(0, str(self.target_dir.absolute()))

            # æ—¢å­˜ã® torch ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¯ãƒªã‚¢ / Clear existing torch modules
            for m in list(sys.modules):
                if m.startswith('torch'):
                    del sys.modules[m]

            import torch
            self.log_output(f"Torch {torch.__version__}, CUDA: {torch.cuda.is_available()}")
            self.log_output("Whisper OK")

            info_file = self.target_dir / "pytorch_whisper_installed.json"
            if info_file.exists():
                info = json.load(open(info_file, "r"))
                self.log_output(f"Installed version: {info.get('version')} @ {info.get('time')}")

            self.update_status(self.t("verify_success"), self.colors['success'])
            messagebox.showinfo(self.t("verify_success"),
                                self.t("verify_success_msg"))
            sys.path = orig

        except ImportError as e:
            self.log_output(f"{self.t('import_error')} {e}")
            self.update_status(self.t("verify_failed"), self.colors['danger'])
            messagebox.showerror(self.t("verify_failed"),
                                 self.t("verify_failed_msg").format(str(e)))
        except Exception as e:
            self.log_output(f"{self.t('error')}: {e}")
            self.update_status(self.t("verify_failed"), self.colors['danger'])
            messagebox.showerror(self.t("error"), str(e))

    def on_closing(self):
        """
        ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‰ã˜ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ / Event triggered on window close
        """
        if self.is_downloading:
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã«é–‰ã˜ã¦ã‚ˆã„ã‹ç¢ºèª / Confirm if user wants to close while downloading
            if not messagebox.askyesno(self.t("confirm"),
                                       self.t("still_downloading")):
                return
        self.root.destroy()

    def run(self):
        """
        ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹ / Start the main GUI loop
        """
        self.root.mainloop()


if __name__ == "__main__":
    app = PyTorchDownloader()
    app.run()